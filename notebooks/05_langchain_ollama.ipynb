{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669fc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52aadad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"gemma3:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569b65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"Who are you ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad9517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m a large language model created by the Gemma team at Google DeepMind. \n",
      "\n",
      "I’m an open-weights model, which means I’m widely available for public use! \n",
      "\n",
      "Essentially, I’m designed to take text and images as input and generate text as output. \n",
      "\n",
      "I can do a lot of things, like:\n",
      "\n",
      "*   Answer your questions\n",
      "*   Write different kinds of creative content (poems, code, scripts, musical pieces, email, letters, etc.)\n",
      "*   Translate languages\n",
      "*   Summarize text\n",
      "\n",
      "How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
